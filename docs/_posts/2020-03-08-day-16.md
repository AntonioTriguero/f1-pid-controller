---
title: "3D Reconstruction #1 - Visor Understanding"
date: 2020-05-12T11:13:00-04:00
categories:
  - logbook
  - 3D Reconstruction
tags:
  - log
  - update
  - 3D
---

This chapter aims to introduce the 3D reconstruction problem and the tool to be used for this practice.

## Environment

The environment is a web application (Unibotics) where the practice will be developed. This application has a 3D viewer that allows to visualize points by calling the function HAL.project3DScene().
to the function HAL.project3DScene(). The scenario is a robot equipped with a stereo vision system with cameras in canonical position (although this assumption cannot be made to solve the exercise).
The scenario is a robot equipped with a stereo vision system with cameras in canonical position (although this assumption cannot be made to solve the exercise since there may be calculation errors) that visualizes a scene formed by figures of different colors and shapes. The robot must be able to obtain the 3D points from the information provided by the stereo cameras.

### Reference systems

The environment handles four reference systems (one in 2D and three in 3D):
- **Image reference system (2D)**: This reference system allows pixel positions in the image plane, it is used to move around the image pixels.
- **Camera reference system (3D)**: This system is implicit in the functions offered by Unibotics and allows to project given points with coordinates with respect to the camera position to points in the image plane (pixels). It also allows to obtain back projection rays from a pixel, thus giving a straight line with respect to the camera position. This system would reference the intrinsic variables of the Pinhole model (ideal camera model).
- **Scene reference system (3D)**: This system is also implicit in Unibotics and allows to position points in the scene with respect to coordinates previously fixed in the scene. By knowing the translation vector and the rotation matrix of the camera with respect to the center of this system, it is possible to project points given in the reference system of the scene into the reference system of the camera and vice versa since both systems are spaces with the same dimensions (three dimensions). The same applies to rear projection rays.
- **Viewfinder reference system (3D)**: This system allows to visualize the points of the scene reference system by projecting them onto the scene reference system. 

### 3D Lines

For this practice it is necessary to understand that a line in space can be defined in two different ways:
- Line defined by two points
- Line defined by a director vector and a point.

To obtain a backprojection ray from a point in the image plane, it will be necessary to first represent that point with respect to the camera reference system (HAL.grafiToOptical()) and then backproject that point in the scene reference system (HAL.backproject()). In this way we have, together with the camera position (HAL.getCameraPosition()), two points in the scene reference system. This translates into a line defined by two points. This line will be the one corresponding to the back projection ray of the pixel expressed in the scene reference frame.
In turn, if you want to project one of these rays from the scene reference system onto the image plane, it will be necessary to project two points of this line (HAL.project()) and then express these coordinates in those of the image plane (HAL.opticalToGrafic()). To obtain two points of the line, they can be calculated from the vector director of that line and the initial point of that vector, for this it is enough to multiply a scalar by the vector and add the initial point. Once the points have been projected, the back projection ray projected on the whole image can be found from the director vector defined by the projected points and the initial point of this vector.

### Epipolar restriction

Having explained how to work with back projection rays to relate information from the two images, the epipolar constraint can be introduced. This constraint imposes that a point in one image must have its counterpart in the other image and this counterpart must belong to the epipolar. The epipolar is the back projection ray of the point projected on the camera where the homologue is located. In this case, since the chambers are in canonical position, the epipoles are in the same row as the point. However, this assumption will not be taken into account when developing an algorithm that works with cameras that are not in canonical position.
In this way, homologous points can be found and once paired, the point in the camera reference system can be obtained by triangulating the back projection rays of both points. The following chapters will explain the triangulation process used and its resolution.

### Next steps

With all this explained, the implementation of the scene reconstruction process can begin. In the following steps you will see the steps to follow and problems that may arise when performing them.
